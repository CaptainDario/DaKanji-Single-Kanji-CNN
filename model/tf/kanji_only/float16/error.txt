---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
E:\projects\DaKanjiRecognizer\.venv_dev\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    209     try:
--> 210       model_str = wrap_toco.wrapped_toco_convert(model_flags_str,
    211                                                  toco_flags_str, input_data_str,

E:\projects\DaKanjiRecognizer\.venv_dev\lib\site-packages\tensorflow\lite\python\wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
     31   """Wraps TocoConvert with lazy loader."""
---> 32   return _pywrap_toco_api.TocoConvert(
     33       model_flags_str,

Exception: <unknown>:0: error: loc(callsite(callsite("DaKanjiRecognizer/conv2D_1_input/Conv2D@__inference__wrapped_model_1048891" at "StatefulPartitionedCall@__inference_signature_wrapper_1049439") at "StatefulPartitionedCall")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x64x64x1xf16>'
<unknown>:0: note: loc("StatefulPartitionedCall"): called from
<unknown>:0: error: loc(callsite(callsite("DaKanjiRecognizer/conv2D_2/Conv2D@__inference__wrapped_model_1048891" at "StatefulPartitionedCall@__inference_signature_wrapper_1049439") at "StatefulPartitionedCall")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x31x31x32xf16>'
<unknown>:0: note: loc("StatefulPartitionedCall"): called from
<unknown>:0: error: loc(callsite(callsite("DaKanjiRecognizer/conv2D_3/Conv2D@__inference__wrapped_model_1048891" at "StatefulPartitionedCall@__inference_signature_wrapper_1049439") at "StatefulPartitionedCall")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x14x14x32xf16>'
<unknown>:0: note: loc("StatefulPartitionedCall"): called from
<unknown>:0: error: loc(callsite(callsite("DaKanjiRecognizer/conv2D_4/Conv2D@__inference__wrapped_model_1048891" at "StatefulPartitionedCall@__inference_signature_wrapper_1049439") at "StatefulPartitionedCall")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x6x6x64xf16>'
<unknown>:0: note: loc("StatefulPartitionedCall"): called from


During handling of the above exception, another exception occurred:

ConverterError                            Traceback (most recent call last)
<ipython-input-15-758d3ba4bcca> in <module>
      7 # Convert the model
      8 converter = tf.lite.TFLiteConverter.from_saved_model(tf_models_dir)
----> 9 tflite_model = converter.convert()
     10 
     11 # Save the model.

E:\projects\DaKanjiRecognizer\.venv_dev\lib\site-packages\tensorflow\lite\python\lite.py in convert(self)
    737     converter_kwargs.update(quant_mode.converter_flags())
    738 
--> 739     result = _convert_saved_model(**converter_kwargs)
    740     calibrate_and_quantize, flags = quant_mode.quantizer_flags()
    741     if calibrate_and_quantize:

E:\projects\DaKanjiRecognizer\.venv_dev\lib\site-packages\tensorflow\lite\python\convert.py in convert_saved_model(saved_model_dir, saved_model_version, saved_model_tags, saved_model_exported_names, **kwargs)
    630     model_flags.saved_model_exported_names.extend(saved_model_exported_names)
    631   toco_flags = build_toco_flags(**kwargs)
--> 632   data = toco_convert_protos(
    633       model_flags.SerializeToString(),
    634       toco_flags.SerializeToString(),

E:\projects\DaKanjiRecognizer\.venv_dev\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    214       return model_str
    215     except Exception as e:
--> 216       raise ConverterError(str(e))
    217 
    218   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:

ConverterError: <unknown>:0: error: loc(callsite(callsite("DaKanjiRecognizer/conv2D_1_input/Conv2D@__inference__wrapped_model_1048891" at "StatefulPartitionedCall@__inference_signature_wrapper_1049439") at "StatefulPartitionedCall")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x64x64x1xf16>'
<unknown>:0: note: loc("StatefulPartitionedCall"): called from
<unknown>:0: error: loc(callsite(callsite("DaKanjiRecognizer/conv2D_2/Conv2D@__inference__wrapped_model_1048891" at "StatefulPartitionedCall@__inference_signature_wrapper_1049439") at "StatefulPartitionedCall")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x31x31x32xf16>'
<unknown>:0: note: loc("StatefulPartitionedCall"): called from
<unknown>:0: error: loc(callsite(callsite("DaKanjiRecognizer/conv2D_3/Conv2D@__inference__wrapped_model_1048891" at "StatefulPartitionedCall@__inference_signature_wrapper_1049439") at "StatefulPartitionedCall")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x14x14x32xf16>'
<unknown>:0: note: loc("StatefulPartitionedCall"): called from
<unknown>:0: error: loc(callsite(callsite("DaKanjiRecognizer/conv2D_4/Conv2D@__inference__wrapped_model_1048891" at "StatefulPartitionedCall@__inference_signature_wrapper_1049439") at "StatefulPartitionedCall")): 'tfl.conv_2d' op operand #0 must be tensor of 32-bit float or QI8 type or QUI8 type or QI16 type values, but got 'tensor<?x6x6x64xf16>'
<unknown>:0: note: loc("StatefulPartitionedCall"): called from


