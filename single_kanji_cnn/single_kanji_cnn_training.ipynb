{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DaKanjiRecognizer - Single Kanji CNN : Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#std lib\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "#ML\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "\n",
    "#creating one hot encodings\n",
    "#from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "#plotting/showing graphics\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data sets are big let's make sure that the GPU is available to speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available:  /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(\"GPUs Available: \", tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a GPU with native 16 bit float support (ex.: RTX-series) is available, enable support for it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the labels for each class from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_1, labels_2, labels = [], [], []\n",
    "\n",
    "# load labels from file\n",
    "with open(r'F:\\data_sets\\etlcdb\\encoding_1.txt', mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    labels_1 = list(eval(f.read()).keys())\n",
    "with open(r'F:\\data_sets\\etlcdb\\encoding_2.txt', mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    labels_2 = list(eval(f.read()).keys())\n",
    "\n",
    "ls = labels_1 + labels_2\n",
    "# order the labels\n",
    "indexs = sorted([str(i) for i in range(0, len(ls))])\n",
    "ordered_labels = [ls[int(i)] for i in indexs]\n",
    "\n",
    "# save the labels to text files\n",
    "with open(r'E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\labels_python_list.txt', mode=\"w+\", encoding=\"utf-8\") as f:\n",
    "    f.write(str(ordered_labels))\n",
    "with open(r'E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\labels.txt', mode=\"w+\", encoding=\"utf-8\") as f:  \n",
    "    f.write(''.join(ordered_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `tf.keras.dataset` from the saved files for test and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch size\n",
    "bs=512\n",
    "# class names\n",
    "classes = [\"%04d\" % i for i in range(len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a font to show japanese characters in matplotlib figures\n",
    "import matplotlib.font_manager as fm\n",
    "show_sample_font = fm.FontProperties(fname=os.path.join(\"..\", \"fonts\", \"NotoSerifCJKjp-Regular.otf\"), size=20)\n",
    "\n",
    "def show_image(img : np.array, label : str):\n",
    "    plt.figure(figsize=(2.2, 2.2))\n",
    "    plt.title(label=label, font=show_sample_font)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.astype(np.float64), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6731099 files belonging to 6543 classes.\n",
      "Using 5721435 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=r'F:\\data_sets\\etlcdb',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=classes,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=bs,\n",
    "    image_size=(64, 64),\n",
    "    validation_split=0.15,\n",
    "    subset=\"training\",\n",
    "    seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset shapes: ((None, 64, 64, 1), (None, 6543)), types: (tf.float16, tf.float16)>\n"
     ]
    }
   ],
   "source": [
    "train = train_dataset.map(\n",
    "    lambda x, y : (tf.cast(x, tf.float16), (tf.cast(y, tf.float16))),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "train = train.cache(r\"F:\\data_sets\\etlcdb_cache\\cache_train\")\n",
    "train = train.shuffle(buffer_size=bs*3)\n",
    "train = train.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "print(train.take(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6731099 files belonging to 6543 classes.\n",
      "Using 1009664 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=r'F:\\data_sets\\etlcdb',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=classes,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=bs,\n",
    "    image_size=(64, 64),\n",
    "    validation_split=0.15,\n",
    "    subset=\"validation\",\n",
    "    seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset shapes: ((None, 64, 64, 1), (None, 6543)), types: (tf.float16, tf.float16)>\n"
     ]
    }
   ],
   "source": [
    "val = val_dataset.map(\n",
    "    lambda x, y : (tf.cast(x, tf.float16), (tf.cast(y, tf.float16))),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "val = val.cache(r\"F:\\data_sets\\etlcdb_cache\\cache_test\")\n",
    "val = val.shuffle(buffer_size=bs*3)\n",
    "val = val.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "print(val.take(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 6543)\n",
      "Model: \"DaKanjiRecognizer_f16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2D_1_2_input (Conv2D)    (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1_1 (Conv2D)          (None, 60, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "maxpool_1 (MaxPooling2D)     (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2_1 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2_2 (Conv2D)          (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "maxpool_2 (MaxPooling2D)     (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3_1 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3_2 (Conv2D)          (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "maxpool_3 (MaxPooling2D)     (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4_1 (Conv2D)          (None, 2, 2, 128)         73856     \n",
      "_________________________________________________________________\n",
      "maxpool_4 (MaxPooling2D)     (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6543)              3356559   \n",
      "_________________________________________________________________\n",
      "softmax_1_output (Softmax)   (None, 6543)              0         \n",
      "=================================================================\n",
      "Total params: 4,105,263\n",
      "Trainable params: 4,105,263\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(name : str):\n",
    "    _model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(input_shape=(64, 64, 1), kernel_size=3, activation='relu', filters=32, name=\"conv2D_1_2_input\"),\n",
    "        tf.keras.layers.Conv2D(kernel_size=3, activation='relu', filters=32, name=\"conv2d_1_1\"),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2, name=\"maxpool_1\"),\n",
    "\n",
    "        tf.keras.layers.Conv2D(kernel_size=3, activation='relu', filters=32, name=\"conv2d_2_1\"),\n",
    "        tf.keras.layers.Conv2D(kernel_size=3, activation='relu', filters=32, name=\"conv2d_2_2\"),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2, name=\"maxpool_2\"),\n",
    "\n",
    "        tf.keras.layers.Conv2D(kernel_size=3, activation='relu', filters=64, name=\"conv2d_3_1\"),\n",
    "        tf.keras.layers.Conv2D(kernel_size=3, activation='relu', filters=64, name=\"conv2d_3_2\"),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2, name=\"maxpool_3\"),\n",
    "\n",
    "        tf.keras.layers.Conv2D(kernel_size=3, activation='relu', filters=128, name=\"conv2d_4_1\"),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2, name=\"maxpool_4\"),\n",
    "\n",
    "        tf.keras.layers.Flatten(name=\"flatten_1\"),\n",
    "        tf.keras.layers.Dropout(0.25, name=\"dropout_1\"),\n",
    "        \n",
    "        tf.keras.layers.Dense(512, name=\"dense_1\"),\n",
    "        tf.keras.layers.Dropout(0.25, name=\"dropout_2\"),\n",
    "\n",
    "        tf.keras.layers.Dense(512, name=\"dense_2\"),\n",
    "        tf.keras.layers.Dropout(0.25, name=\"dropout_3\"),\n",
    "        \n",
    "        tf.keras.layers.Dense(512, name=\"dense_3\"),\n",
    "        tf.keras.layers.Dropout(0.25, name=\"dropout_4\"),\n",
    "\n",
    "        tf.keras.layers.Dense(len(labels), name=\"dense_4\"),\n",
    "\n",
    "        #set the dtype to float32 for numerical stability\n",
    "        tf.keras.layers.Softmax(dtype=\"float32\", name=\"softmax_1_output\") \n",
    "    ], name=name)\n",
    "    \n",
    "    return _model\n",
    "\n",
    "\n",
    "f16_model = get_model(\"DaKanjiRecognizer_f16\")\n",
    "print(f16_model.output_shape)\n",
    "f16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_dir: E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\n"
     ]
    }
   ],
   "source": [
    "#path where the model should be saved\n",
    "model_dir = os.path.join(os.getcwd(), \"model\")\n",
    "print(\"model_dir:\", model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the optimizer, loss function and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001,\n",
    "                                beta_1=0.9,\n",
    "                                beta_2=0.999,\n",
    "                                epsilon=1e-08,)\n",
    "\n",
    "f16_model.compile(optimizer=opt,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optionally load stored weights to resume training\n",
    "#f16_model.load_weights(os.path.join(model_dir, \"tf\", \"checkpoints\", \"weights-improvement-145-0.98.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints dir: E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\n"
     ]
    }
   ],
   "source": [
    "#checkpoints setup\n",
    "filepath = os.path.join(model_dir, \"tf\", \"checkpoints\", \"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(\"checkpoints dir:\", filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally enable tensorboard to track the progress of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "tensorboard log dir: E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\logs\\20210607-220920\n"
     ]
    }
   ],
   "source": [
    "# load the tensorboard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# add the tensorboard callback\n",
    "log_dir = os.path.join(model_dir, \"tf\", \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "callbacks_list.append(tensorboard_callback)\n",
    "\n",
    "#set the path to the tensorboard executable\n",
    "#%env TENSORBOARD_BINARY E:\\\\projects\\\\DaKanjiRecognizerML\\\\.venv\\\\Scripts\\\\tensorboard.exe\n",
    "#%tensorboard --logdir log_dir\n",
    "\n",
    "print(\"tensorboard log dir:\", log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally train the model on the data set (in case of an Interrupt creates checkpoints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "11175/11175 [==============================] - 184s 16ms/step - loss: 6.7200 - accuracy: 0.0405 - val_loss: 3.9112 - val_accuracy: 0.2591\n",
      "\n",
      "Epoch 00051: val_accuracy improved from -inf to 0.25914, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-51-0.26.hdf5\n",
      "Epoch 52/100\n",
      "11175/11175 [==============================] - 179s 16ms/step - loss: 3.8649 - accuracy: 0.2399 - val_loss: 2.2763 - val_accuracy: 0.5483\n",
      "\n",
      "Epoch 00052: val_accuracy improved from 0.25914 to 0.54825, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-52-0.55.hdf5\n",
      "Epoch 53/100\n",
      "11175/11175 [==============================] - 177s 16ms/step - loss: 2.7848 - accuracy: 0.4115 - val_loss: 1.7012 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00053: val_accuracy improved from 0.54825 to 0.66276, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-53-0.66.hdf5\n",
      "Epoch 54/100\n",
      "11175/11175 [==============================] - 179s 16ms/step - loss: 2.2586 - accuracy: 0.5108 - val_loss: 1.3641 - val_accuracy: 0.7291\n",
      "\n",
      "Epoch 00054: val_accuracy improved from 0.66276 to 0.72911, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-54-0.73.hdf5\n",
      "Epoch 55/100\n",
      "11175/11175 [==============================] - 175s 15ms/step - loss: 1.9509 - accuracy: 0.5710 - val_loss: 1.1927 - val_accuracy: 0.7639\n",
      "\n",
      "Epoch 00055: val_accuracy improved from 0.72911 to 0.76385, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-55-0.76.hdf5\n",
      "Epoch 56/100\n",
      "11175/11175 [==============================] - 178s 16ms/step - loss: 1.7573 - accuracy: 0.6108 - val_loss: 1.0748 - val_accuracy: 0.7845\n",
      "\n",
      "Epoch 00056: val_accuracy improved from 0.76385 to 0.78447, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-56-0.78.hdf5\n",
      "Epoch 57/100\n",
      "11175/11175 [==============================] - 178s 16ms/step - loss: 1.6186 - accuracy: 0.6402 - val_loss: 0.9819 - val_accuracy: 0.8041\n",
      "\n",
      "Epoch 00057: val_accuracy improved from 0.78447 to 0.80411, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-57-0.80.hdf5\n",
      "Epoch 58/100\n",
      "11175/11175 [==============================] - 174s 15ms/step - loss: 1.5122 - accuracy: 0.6622 - val_loss: 0.9353 - val_accuracy: 0.8126\n",
      "\n",
      "Epoch 00058: val_accuracy improved from 0.80411 to 0.81261, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-58-0.81.hdf5\n",
      "Epoch 59/100\n",
      "11175/11175 [==============================] - 189s 17ms/step - loss: 1.4350 - accuracy: 0.6793 - val_loss: 0.8922 - val_accuracy: 0.8239\n",
      "\n",
      "Epoch 00059: val_accuracy improved from 0.81261 to 0.82394, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-59-0.82.hdf5\n",
      "Epoch 60/100\n",
      "11175/11175 [==============================] - 181s 16ms/step - loss: 1.3702 - accuracy: 0.6930 - val_loss: 0.8586 - val_accuracy: 0.8274\n",
      "\n",
      "Epoch 00060: val_accuracy improved from 0.82394 to 0.82743, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-60-0.83.hdf5\n",
      "Epoch 61/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 1.3194 - accuracy: 0.7038 - val_loss: 0.8255 - val_accuracy: 0.8399\n",
      "\n",
      "Epoch 00061: val_accuracy improved from 0.82743 to 0.83990, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-61-0.84.hdf5\n",
      "Epoch 62/100\n",
      "11175/11175 [==============================] - 182s 16ms/step - loss: 1.2794 - accuracy: 0.7127 - val_loss: 0.7846 - val_accuracy: 0.8460\n",
      "\n",
      "Epoch 00062: val_accuracy improved from 0.83990 to 0.84596, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-62-0.85.hdf5\n",
      "Epoch 63/100\n",
      "11175/11175 [==============================] - 179s 16ms/step - loss: 1.2392 - accuracy: 0.7215 - val_loss: 0.7698 - val_accuracy: 0.8511\n",
      "\n",
      "Epoch 00063: val_accuracy improved from 0.84596 to 0.85107, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-63-0.85.hdf5\n",
      "Epoch 64/100\n",
      "11175/11175 [==============================] - 176s 15ms/step - loss: 1.2073 - accuracy: 0.7288 - val_loss: 0.7567 - val_accuracy: 0.8531\n",
      "\n",
      "Epoch 00064: val_accuracy improved from 0.85107 to 0.85308, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-64-0.85.hdf5\n",
      "Epoch 65/100\n",
      "11175/11175 [==============================] - 180s 16ms/step - loss: 1.1786 - accuracy: 0.7350 - val_loss: 0.7400 - val_accuracy: 0.8579\n",
      "\n",
      "Epoch 00065: val_accuracy improved from 0.85308 to 0.85785, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-65-0.86.hdf5\n",
      "Epoch 66/100\n",
      "11175/11175 [==============================] - 181s 16ms/step - loss: 1.1548 - accuracy: 0.7406 - val_loss: 0.7277 - val_accuracy: 0.8594\n",
      "\n",
      "Epoch 00066: val_accuracy improved from 0.85785 to 0.85939, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-66-0.86.hdf5\n",
      "Epoch 67/100\n",
      "11175/11175 [==============================] - 176s 15ms/step - loss: 1.1302 - accuracy: 0.7461 - val_loss: 0.7060 - val_accuracy: 0.8647\n",
      "\n",
      "Epoch 00067: val_accuracy improved from 0.85939 to 0.86475, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-67-0.86.hdf5\n",
      "Epoch 68/100\n",
      "11175/11175 [==============================] - 171s 15ms/step - loss: 1.1084 - accuracy: 0.7512 - val_loss: 0.7127 - val_accuracy: 0.8646\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.86475\n",
      "Epoch 69/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 1.0917 - accuracy: 0.7556 - val_loss: 0.6853 - val_accuracy: 0.8685\n",
      "\n",
      "Epoch 00069: val_accuracy improved from 0.86475 to 0.86848, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-69-0.87.hdf5\n",
      "Epoch 70/100\n",
      "11175/11175 [==============================] - 173s 15ms/step - loss: 1.0766 - accuracy: 0.7584 - val_loss: 0.6732 - val_accuracy: 0.8698\n",
      "\n",
      "Epoch 00070: val_accuracy improved from 0.86848 to 0.86980, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-70-0.87.hdf5\n",
      "Epoch 71/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 1.0580 - accuracy: 0.7624 - val_loss: 0.6518 - val_accuracy: 0.8765\n",
      "\n",
      "Epoch 00071: val_accuracy improved from 0.86980 to 0.87647, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-71-0.88.hdf5\n",
      "Epoch 72/100\n",
      "11175/11175 [==============================] - 169s 15ms/step - loss: 1.0431 - accuracy: 0.7663 - val_loss: 0.6545 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.87647\n",
      "Epoch 73/100\n",
      "11175/11175 [==============================] - 169s 15ms/step - loss: 1.0320 - accuracy: 0.7688 - val_loss: 0.6467 - val_accuracy: 0.8766\n",
      "\n",
      "Epoch 00073: val_accuracy improved from 0.87647 to 0.87665, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-73-0.88.hdf5\n",
      "Epoch 74/100\n",
      "11175/11175 [==============================] - 167s 15ms/step - loss: 1.0202 - accuracy: 0.7717 - val_loss: 0.6404 - val_accuracy: 0.8780\n",
      "\n",
      "Epoch 00074: val_accuracy improved from 0.87665 to 0.87800, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-74-0.88.hdf5\n",
      "Epoch 75/100\n",
      "11175/11175 [==============================] - 167s 15ms/step - loss: 1.0063 - accuracy: 0.7749 - val_loss: 0.6322 - val_accuracy: 0.8794\n",
      "\n",
      "Epoch 00075: val_accuracy improved from 0.87800 to 0.87944, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-75-0.88.hdf5\n",
      "Epoch 76/100\n",
      "11175/11175 [==============================] - 167s 15ms/step - loss: 0.9966 - accuracy: 0.7773 - val_loss: 0.6365 - val_accuracy: 0.8806\n",
      "\n",
      "Epoch 00076: val_accuracy improved from 0.87944 to 0.88059, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-76-0.88.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 0.9871 - accuracy: 0.7790 - val_loss: 0.6106 - val_accuracy: 0.8850\n",
      "\n",
      "Epoch 00077: val_accuracy improved from 0.88059 to 0.88502, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-77-0.89.hdf5\n",
      "Epoch 78/100\n",
      "11175/11175 [==============================] - 167s 15ms/step - loss: 0.9799 - accuracy: 0.7812 - val_loss: 0.6186 - val_accuracy: 0.8839\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.88502\n",
      "Epoch 79/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 0.9687 - accuracy: 0.7834 - val_loss: 0.6120 - val_accuracy: 0.8860\n",
      "\n",
      "Epoch 00079: val_accuracy improved from 0.88502 to 0.88598, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-79-0.89.hdf5\n",
      "Epoch 80/100\n",
      "11175/11175 [==============================] - 167s 15ms/step - loss: 0.9618 - accuracy: 0.7849 - val_loss: 0.6135 - val_accuracy: 0.8839\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.88598\n",
      "Epoch 81/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 0.9558 - accuracy: 0.7867 - val_loss: 0.6120 - val_accuracy: 0.8855\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.88598\n",
      "Epoch 82/100\n",
      "11175/11175 [==============================] - 167s 15ms/step - loss: 0.9480 - accuracy: 0.7890 - val_loss: 0.6051 - val_accuracy: 0.8878\n",
      "\n",
      "Epoch 00082: val_accuracy improved from 0.88598 to 0.88780, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-82-0.89.hdf5\n",
      "Epoch 83/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 0.9440 - accuracy: 0.7895 - val_loss: 0.5824 - val_accuracy: 0.8895\n",
      "\n",
      "Epoch 00083: val_accuracy improved from 0.88780 to 0.88952, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-83-0.89.hdf5\n",
      "Epoch 84/100\n",
      "11175/11175 [==============================] - 167s 15ms/step - loss: 0.9355 - accuracy: 0.7909 - val_loss: 0.5972 - val_accuracy: 0.8884\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.88952\n",
      "Epoch 85/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 0.9299 - accuracy: 0.7928 - val_loss: 0.5908 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00085: val_accuracy improved from 0.88952 to 0.88987, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-85-0.89.hdf5\n",
      "Epoch 86/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 0.9249 - accuracy: 0.7941 - val_loss: 0.5838 - val_accuracy: 0.8922\n",
      "\n",
      "Epoch 00086: val_accuracy improved from 0.88987 to 0.89219, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-86-0.89.hdf5\n",
      "Epoch 87/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 0.9188 - accuracy: 0.7955 - val_loss: 0.5756 - val_accuracy: 0.8919\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.89219\n",
      "Epoch 88/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 0.9148 - accuracy: 0.7964 - val_loss: 0.5778 - val_accuracy: 0.8938\n",
      "\n",
      "Epoch 00088: val_accuracy improved from 0.89219 to 0.89383, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-88-0.89.hdf5\n",
      "Epoch 89/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 0.9101 - accuracy: 0.7976 - val_loss: 0.5754 - val_accuracy: 0.8928\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.89383\n",
      "Epoch 90/100\n",
      "11175/11175 [==============================] - 167s 15ms/step - loss: 0.9044 - accuracy: 0.7985 - val_loss: 0.5842 - val_accuracy: 0.8907\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.89383\n",
      "Epoch 91/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 0.9003 - accuracy: 0.7996 - val_loss: 0.5778 - val_accuracy: 0.8938\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.89383\n",
      "Epoch 92/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 0.8957 - accuracy: 0.8013 - val_loss: 0.5695 - val_accuracy: 0.8942\n",
      "\n",
      "Epoch 00092: val_accuracy improved from 0.89383 to 0.89417, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-92-0.89.hdf5\n",
      "Epoch 93/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 0.8923 - accuracy: 0.8019 - val_loss: 0.5611 - val_accuracy: 0.8947\n",
      "\n",
      "Epoch 00093: val_accuracy improved from 0.89417 to 0.89467, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-93-0.89.hdf5\n",
      "Epoch 94/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 0.8882 - accuracy: 0.8026 - val_loss: 0.5705 - val_accuracy: 0.8949\n",
      "\n",
      "Epoch 00094: val_accuracy improved from 0.89467 to 0.89494, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-94-0.89.hdf5\n",
      "Epoch 95/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 0.8862 - accuracy: 0.8034 - val_loss: 0.5633 - val_accuracy: 0.8962\n",
      "\n",
      "Epoch 00095: val_accuracy improved from 0.89494 to 0.89624, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-95-0.90.hdf5\n",
      "Epoch 96/100\n",
      "11175/11175 [==============================] - 169s 15ms/step - loss: 0.8817 - accuracy: 0.8040 - val_loss: 0.5749 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.89624\n",
      "Epoch 97/100\n",
      "11175/11175 [==============================] - 168s 15ms/step - loss: 0.8772 - accuracy: 0.8053 - val_loss: 0.5566 - val_accuracy: 0.8972\n",
      "\n",
      "Epoch 00097: val_accuracy improved from 0.89624 to 0.89716, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-97-0.90.hdf5\n",
      "Epoch 98/100\n",
      "11175/11175 [==============================] - 167s 15ms/step - loss: 0.8763 - accuracy: 0.8057 - val_loss: 0.5535 - val_accuracy: 0.8976\n",
      "\n",
      "Epoch 00098: val_accuracy improved from 0.89716 to 0.89764, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-98-0.90.hdf5\n",
      "Epoch 99/100\n",
      "11175/11175 [==============================] - 169s 15ms/step - loss: 0.8713 - accuracy: 0.8068 - val_loss: 0.5473 - val_accuracy: 0.8981\n",
      "\n",
      "Epoch 00099: val_accuracy improved from 0.89764 to 0.89812, saving model to E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\checkpoints\\weights-improvement-99-0.90.hdf5\n",
      "Epoch 100/100\n",
      "11175/11175 [==============================] - 169s 15ms/step - loss: 0.8700 - accuracy: 0.8073 - val_loss: 0.5500 - val_accuracy: 0.8981\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.89812\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "hist = f16_model.fit(\n",
    "    train,\n",
    "    validation_data=val,\n",
    "    epochs=100,\n",
    "    initial_epoch=50,\n",
    "    workers=16,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "\n",
    "After training plot the loss and accuracy for the test and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs look good.\n",
    "Let's now make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ゆ', 'ゅ', '屮', '幼', '衂', '四', '叨', '血', '甥', 'め']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 158.4x158.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = tf.keras.preprocessing.image.load_img(\n",
    "    path= r\"F:\\data_sets\\etlcdb\\0100\\10.jpg\",\n",
    "    color_mode=\"grayscale\"\n",
    ")\n",
    "sample = tf.keras.preprocessing.image.img_to_array(sample)\n",
    "sample = sample.reshape((1, 64, 64, 1))\n",
    "\n",
    "# output 10 most liekly predictions\n",
    "prediction = f16_model.predict(sample)[0]\n",
    "ind = np.argpartition(prediction, -10)[-10:]\n",
    "q = ind[np.argsort(prediction[ind])]\n",
    "print([ordered_labels[i] for i in reversed(q)])\n",
    "\n",
    "show_image(sample.reshape((64, 64)), ordered_labels[prediction.argmax()] + \" - %.2f\" % prediction.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "\n",
    "The model is perfoming very well therefore save the trained model as a \"*.pb\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) conv2D_1_2_input_input with unsupported characters which will be renamed to conv2d_1_2_input_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\trained_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:\\projects\\DaKanjiRecognizerML\\single_kanji_cnn\\model\\tf\\trained_model\\assets\n"
     ]
    }
   ],
   "source": [
    "f16_model.save(os.path.join(model_dir, \"tf\", \"trained_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a float32 model with the same weights as the mixed_float16 model, so\n",
    "# that it loads into TF Lite\n",
    "policy = tf.keras.mixed_precision.global_policy()\n",
    "tf.keras.mixed_precision.set_global_policy(\"float32\")\n",
    "f32_model = get_model(\"DaKanjiRecognizer_f32\")\n",
    "f32_model.set_weights(f16_model.get_weights())\n",
    "#f32_model.summary()\n",
    "tf.keras.mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally convert the model to a TF-Light model to be used in other applications ([DaKanjiRecognizer Desktop](https://github.com/CaptainDario/DaKanjiRecognizer-Desktop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) conv2D_1_2_input_input with unsupported characters which will be renamed to conv2d_1_2_input_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dario\\AppData\\Local\\Temp\\tmp0_8ibwdm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\dario\\AppData\\Local\\Temp\\tmp0_8ibwdm\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(f32_model) # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(os.path.join(model_dir, \"tflite\", \"model.tflite\"), 'wb') as f:\n",
    "  f.write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
